# 前言

在上一章中，我们已经学会了如何配置参数。在这一章中，我们将设计一个Gain效果器，通过**多种不同的实现方式**来介绍参数的获取和Real-Time效果器的DSP部分基本写作逻辑。

# 准备工作

根据之前的教程创建好工程并配置好我们这次需要的参数——Gain：

```cpp
juce::AudioProcessorValueTreeState::ParameterLayout TaroGainAudioProcessor::createParameterLayout()
{
    APVTS::ParameterLayout layout;

    using namespace juce;
    
    layout.add(std::make_unique<AudioParameterFloat>("Gain",
                                                     "Gain(dB)",
                                                     NormalisableRange<float>(-10.f, 10.f, 0.1f, 1), 0.f));
    
    return layout;
}
```

# processBlock

到达Real-Time效果器最高城！processBlock！

让我们先看看它默认长什么样：

```cpp
void AudioProcessor::processBlock (juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages)
{
    juce::ScopedNoDenormals noDenormals;
    auto totalNumInputChannels  = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();

    // In case we have more outputs than inputs, this code clears any output
    // channels that didn't contain input data, (because these aren't
    // guaranteed to be empty - they may contain garbage).
    // This is here to avoid people getting screaming feedback
    // when they first compile a plugin, but obviously you don't need to keep
    // this code if your algorithm always overwrites all the output channels.
    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear (i, 0, buffer.getNumSamples());

    // This is the place where you'd normally do the guts of your plugin's
    // audio processing...
    // Make sure to reset the state if your inner loop is processing
    // the samples and the outer loop is handling the channels.
    // Alternatively, you can process the samples with the channels
    // interleaved by keeping the same state.
    for (int channel = 0; channel < totalNumInputChannels; ++channel)
    {
        auto* channelData = buffer.getWritePointer (channel);

        // ..do something to the data...
    }
}
```

---

首先是：

```cpp
juce::ScopedNoDenormals noDenormals;
```

很好，第一行代码就完全不知道它在说什么。

它的意思其实是禁用当前作用域下的浮点数的非规格化处理，可能有点绕口，但是这能在部分情况下显著提升音频的处理速度，当然也会伴随着一些负面影响。

关于具体什么是浮点数的规格化和非规格化处理，以及它们分别有什么利弊，可以查看以下这位老师的博客，讲解的十分清晰：

http://cenalulu.github.io/linux/about-denormalized-float-number/

**当然，如果你并不在乎为什么需要这行代码，我也鼓励你直接跳过来节省时间。**

---

```cpp
auto totalNumInputChannels  = getTotalNumInputChannels();
auto totalNumOutputChannels = getTotalNumOutputChannels();
```

获取了输入通道的数量和输出通道的数量。

---

```cpp
for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
    buffer.clear (i, 0, buffer.getNumSamples());
```

将多余的输出通道内容置零，以防止啸叫产生。

---

```cpp
for (int channel = 0; channel < totalNumInputChannels; ++channel)
{
    auto* channelData = buffer.getWritePointer (channel);

    // ..do something to the data...
}
```

遍历所有的输入通道，并获取指向该通道下buffer的头部的指针，同时也是最关键的部分。

# Gain

想必Gain（增益）效果器是什么东西应该不用再具体介绍了吧？我们可以通过Gain来控制音频的响度。

接下来将用四种不同的方式来实现这个效果

## 方式一



```cpp
void TaroGainAudioProcessor::processBlock (juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages)
{
    juce::ScopedNoDenormals noDenormals;
    auto totalNumInputChannels  = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();

    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());

    float currentGain = *apvts.getRawParameterValue("Gain");

    for (int channel = 0; channel < totalNumInputChannels; ++channel)
    {
        auto* channelData = buffer.getWritePointer (channel);

        for (int sample = 0; sample < buffer.getNumSamples(); ++sample)
				{
						channelData[sample] *= juce::Decibels::decibelsToGain(currentGain);
				}
    }
}
```

## 方式二

```cpp
void TaroGainAudioProcessor::processBlock (juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages)
{
    juce::ScopedNoDenormals noDenormals;
    auto totalNumInputChannels  = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();

    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());

    float currentGain = *apvts.getRawParameterValue("Gain");

    juce::dsp::AudioBlock<float> block(buffer);
    for (int channel = 0; channel < block.getNumChannels(); ++channel)
    {
				auto* channelData = block.getChannelPointer(channel);
        for (int sample = 0; sample < block.getNumSamples(); ++sample)
        {
						channelData[sample] *= juce::Decibels::decibelsToGain(currentGain);
				}
		}
}
```

## 方式三

```cpp
void TaroGainAudioProcessor::processBlock (juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages)
{
    juce::ScopedNoDenormals noDenormals;
    auto totalNumInputChannels  = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();

    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());

    float currentGain = *apvts.getRawParameterValue("Gain");

    buffer.applyGain(juce::Decibels::decibelsToGain(currentGain));
}
```

## 方式四

```cpp
void TaroGainAudioProcessor::processBlock (juce::AudioBuffer<float>& buffer, juce::MidiBuffer& midiMessages)
{
    juce::ScopedNoDenormals noDenormals;
    auto totalNumInputChannels  = getTotalNumInputChannels();
    auto totalNumOutputChannels = getTotalNumOutputChannels();

    for (auto i = totalNumInputChannels; i < totalNumOutputChannels; ++i)
        buffer.clear(i, 0, buffer.getNumSamples());

    float currentGain = *apvts.getRawParameterValue("Gain");

    juce::dsp::AudioBlock<float> block(buffer);
    gain.setGainDecibels(currentGain);
    gain.process(juce::dsp::ProcessContextReplacing<float>(block));
}
```

